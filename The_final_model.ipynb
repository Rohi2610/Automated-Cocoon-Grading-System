{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f59832a6-987c-4370-b966-4423c5fe7b15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from skimage.measure import label, regionprops\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b1d965-2ab0-4307-9084-085e8f64a3e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Length_predictor(length, ratio):\n",
    "    Length_model = joblib.load(\"Length_predictor.joblib\")\n",
    "    Length_cm = Length_model.predict([[length, ratio]])[0]\n",
    "    return Length_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "125fbcc0-2523-4d0f-a041-c56669407b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Width_predictor(width):\n",
    "    Width_model = joblib.load(\"Width_predictor.joblib\")\n",
    "    Width_cm = Width_model.predict([[width]])[0]\n",
    "    return Width_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "152e7ab3-f170-44cd-9d4f-86697f0297b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Volume_predictor(length, breadth):\n",
    "    Volume_model = joblib.load(\"Volume_predictor_1.joblib\")\n",
    "    Volume = Volume_model.predict([[length, breadth]])[0]\n",
    "    return Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfaaaafb-de47-4655-8c36-ace38330281e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Shell_Weight_predictor(Volume):\n",
    "    Shell_Weight_model = joblib.load(\"Shell_Weight_predictor_1.joblib\")\n",
    "    Shell_Weight = Shell_Weight_model.predict([[Volume]])[0]\n",
    "    return Shell_Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f193f0cb-34af-499f-8ee9-5b40ddea19f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Grading(Shell_Weight):\n",
    "    Grading_model = joblib.load(\"Grading.joblib\")\n",
    "    Grade = Grading_model.predict([[Shell_Weight]])[0]\n",
    "    return Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aa49fda-df97-4bbc-8f80-0e5a1325aba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_contours_from_yolo(img_path, model_path):\n",
    "    # Load the YOLOv8 model\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    # Load and preprocess the input image\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Check if the image is loaded correctly\n",
    "    if img is None:\n",
    "        raise ValueError(\"Image not found or the path is incorrect.\")\n",
    "    \n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "\n",
    "    # Check if the image is grayscale or color\n",
    "    if len(img.shape) == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "    H, W, _ = img.shape\n",
    "\n",
    "    # Inference with the YOLOv8 model\n",
    "    results = model(img)\n",
    "\n",
    "    contours_list = []\n",
    "    bounding_rects = []\n",
    "\n",
    "    # Process each detection in the results\n",
    "    for result in results:\n",
    "        for j, mask in enumerate(result.masks.data):\n",
    "            mask = mask.cpu().numpy().astype(np.uint8) * 255  # Convert to 8-bit binary mask\n",
    "\n",
    "            # Check if mask is empty\n",
    "            if mask.size == 0:\n",
    "                raise ValueError(\"Mask is empty. Please check the model's output.\")\n",
    "            \n",
    "            # print(f\"Mask shape before resize: {mask.shape}\")\n",
    "\n",
    "            # Resize mask to the original image size\n",
    "            mask = cv2.resize(mask, (W, H))\n",
    "\n",
    "            # print(f\"Mask shape after resize: {mask.shape}\")\n",
    "\n",
    "            # Find the contours of the mask\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            if not contours:\n",
    "                raise ValueError(\"No contours found in the mask. Please check the mask and try again.\")\n",
    "            \n",
    "            contours_list.append(contours)\n",
    "            \n",
    "            # Compute bounding rectangles for each contour\n",
    "            for contour in contours:\n",
    "                x, y, width, height = cv2.boundingRect(contour)\n",
    "                bounding_rects.append((x, y, width, height))\n",
    "                \n",
    "                # # Optional: Draw the contour and bounding rectangle on the original image for visualization\n",
    "                # cv2.drawContours(img, [contour], -1, (0, 255, 0), 2)\n",
    "                # cv2.rectangle(img, (x, y), (x+width, y+height), (255, 0, 0), 2)\n",
    "                # cv2.imshow('Mask Contours and Bounding Rectangles', img)\n",
    "                # cv2.waitKey(0)\n",
    "                # cv2.destroyAllWindows()\n",
    "            \n",
    "    return contours_list, bounding_rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2005885a-72e1-4e63-8e38-6f8722f747b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_cocoon_1(bounding_rects):\n",
    "    \n",
    "    for i, rect in enumerate(bounding_rects):\n",
    "        x, y, w, h = rect\n",
    "        # print(f\"Bounding rectangle {i}: x={x}, y={y}, width={w}, height={h}\")\n",
    "        print(w, h)\n",
    "        length_cm = w * 0.0264583333  # Example conversion factor\n",
    "        breadth_cm = h * 0.0264583333  # Example conversion factor\n",
    "        ratio = 4.19460691\n",
    "        length = Length_predictor(length_cm, ratio)\n",
    "        width = Width_predictor(breadth_cm)\n",
    "        volume = Volume_predictor(length, width)\n",
    "        shell_weight = Shell_Weight_predictor(volume)\n",
    "        # grade = Grading(shell_weight)\n",
    "        # print(f\"Length: {length_cm} cm, Breadth: {breadth_cm} cm, Volume: {volume} cm^3, Shell Weight: {shell_weight} g, Grade: {grade}\")\n",
    "        return length_cm ,breadth_cm, length ,width , volume, shell_weight\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "884d3834-bf6f-4f46-94fd-2dbb8aed82ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter image path:  /Users/KIIT/Desktop/Research/CTR&TI/Paper/ppt/DSC04385.JPG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (2813, 2053, 3)\n",
      "\n",
      "0: 640x480 1 Cocoon, 554.2ms\n",
      "Speed: 9.7ms preprocess, 554.2ms inference, 16.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "902 1490\n",
      "Predicted Length: 23.865416636600003 cm, Predicted_Breadth: 39.422916617 cm, Real length: 5.686475479793893, Real width: 2.9175010684183, Volume: 30.809532802113957 cm^3, Shell Weight: 1.6285789048455188 g\n"
     ]
    }
   ],
   "source": [
    "image_path = input(\"Enter image path: \")\n",
    "model_path = '/Users/KIIT/Desktop/Research/CTR&TI/Models/runs/segment/train32/weights/last.pt'  # Path to your trained YOLOv8 model\n",
    "\n",
    "contours_list, bounding_rects = find_contours_from_yolo(image_path, model_path)\n",
    "\n",
    "# for i, contours in enumerate(contours_list):\n",
    "#     print(f\"Contours for mask {i}: {contours}\")\n",
    "\n",
    "length_cm, breadth_cm, length, width, volume, shell_weight = predict_cocoon_1(bounding_rects)\n",
    "print(f\"Predicted Length: {length_cm} cm, Predicted_Breadth: {breadth_cm} cm, Real length: {length}, Real width: {width}, Volume: {volume} cm^3, Shell Weight: {shell_weight} g\")\n",
    "# csv.data[length, breadth, volume, shell_weight, grade]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1a016c5-91f5-408b-b433-4cdb36d85ffe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_cocoon(img):\n",
    "    model_path = '/Users/KIIT/Desktop/Research/CTR&TI/Models/runs/segment/train32/weights/last.pt'\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "          print(\"Error: Could not read image!\")\n",
    "  \n",
    "    print(img.shape)\n",
    "    \n",
    "    if len(img.shape) == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "    H, W, _ = img.shape\n",
    "    print(H)\n",
    "    print(W)\n",
    "    # image = load_img(img_path, target_size=(480, 640))  # Change target size to match your model's input size\n",
    "    img = img_to_array(img) / 255.0\n",
    "    img = np.expand_dims(img, axis=0) \n",
    "\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    results = model(img)\n",
    "\n",
    "    for result in results:\n",
    "        for j, mask in enumerate(result.masks.data):\n",
    "\n",
    "            mask = mask.cpu().numpy().astype(np.uint8) * 255\n",
    "            if mask.size == 0:\n",
    "                    raise ValueError(\"Mask is empty. Please check the model's output.\")\n",
    "\n",
    "            mask = cv2.resize(mask, (H, W))\n",
    "\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "            if not contours:\n",
    "                raise ValueError(\"No contours found in the mask. Please check the mask and try again.\")\n",
    "\n",
    "            cocoon_contour = max(contours, key=cv2.contourArea)\n",
    "            # cv2.imwrite('./output.png', mask)\n",
    "            x, y, width, height = cv2.boundingRect(cocoon_contour)\n",
    "\n",
    "            # Convert pixel measurements to centimeters (assuming you know the conversion factor)\n",
    "            cm_per_pixel = 0.0264583333  # Example value, you need to calibrate this\n",
    "            length_cm = width*cm_per_pixel\n",
    "            breadth_cm = height*cm_per_pixel\n",
    "\n",
    "            # print(f\"Length: {length_cm} cm, Breadth: {breadth_cm} cm\")\n",
    "\n",
    "            Volume = Volume_predictor(length_cm, breadth_cm)\n",
    "\n",
    "            Shell_Weight = Shell_Weight_predictor(Volume)\n",
    "\n",
    "            Grade = Grading(Shell_Weight)\n",
    "\n",
    "            return length_cm, breadth_cm, Volume, Shell_Weight, Grade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03110d7c-0f80-4cc3-8d23-01b9a60319ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComparision.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/KIIT/Desktop/Research/CTR&TI/Models/runs/segment/train32/weights/last.pt\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Path to your trained YOLOv8 model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter folder path:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m Original_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/The_final_dataset_1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     11\u001b[0m creating_csv(model_path, csv_file_path, folder_path, Original_file_path)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1267\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "csv_file_path = \"Comparision.csv\"\n",
    "\n",
    "model_path = '/Users/KIIT/Desktop/Research/CTR&TI/Models/runs/segment/train32/weights/last.pt'  # Path to your trained YOLOv8 model\n",
    "\n",
    "folder_path = input(\"Enter folder path:\")\n",
    "\n",
    "Original_file_path = 'dataset/The_final_dataset_1.csv'\n",
    "\n",
    "creating_csv(model_path, csv_file_path, folder_path, Original_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d7f60286-6865-4ca2-9fab-f4257f1a4c75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def creating_csv(model_path, csv_file_path, folder_path, Original_file_path):\n",
    "    \n",
    "    headers = ['S.No.','filename','Length (cm)', 'Original Length', 'Width (cm)', 'Original Width', 'Volume (cm^3)', 'Original Volume', 'Shell Weight (g)', 'Original Shell Weight']\n",
    "    csv_data = []\n",
    "    \n",
    "    file = pd.read_csv(Original_file_path)\n",
    "    \n",
    "    Original_Length = file['Cocoon length(cm)']\n",
    "    Original_Width = file['mean width(cm)']\n",
    "    Original_Volume = file['Cocoon Volume (cm3)']\n",
    "    Original_Shell_Weight = file['Shell Weight']\n",
    "    \n",
    "    Original_Length = Original_Length[103: 441].tolist()\n",
    "    Original_Width = Original_Width[103: 441].tolist()\n",
    "    Original_Volume = Original_Volume[103: 441].tolist()\n",
    "    Original_Shell_Weight = Original_Shell_Weight[103: 441].tolist()\n",
    "    \n",
    "    j=0\n",
    "    i=0\n",
    "    k=0\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".JPG\") or filename.endswith(\".png\"):  # Add other image formats if needed\n",
    "            # print('twill')\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            contours_list, bounding_rects = find_contours_from_yolo(image_path, model_path)\n",
    "            \n",
    "            length_cm, breadth_cm, length, width, volume, shell_weight = predict_cocoon_1(bounding_rects)\n",
    "            \n",
    "            if(i%2!=0):\n",
    "                csv_data.append([i, filename, length, j, width, j, volume, j, shell_weight, j])\n",
    "                print(csv_data[i])\n",
    "            else:\n",
    "                csv_data.append([i, filename, length, Original_Length[k], width, Original_Width[k], volume, Original_Volume[k], shell_weight, Original_Shell_Weight[k]])\n",
    "                print(csv_data[i])\n",
    "                k=k+1\n",
    "            print(i)\n",
    "            i=i+1\n",
    "            \n",
    "#             try:\n",
    "#                 contours_list, bounding_rects = find_contours_from_yolo(image_path, model_path)\n",
    "#                 length, breadth, volume, shell_weight, grade = predict_cocoon_1(bounding_rects)\n",
    "#                 print(\"Picture:\",filename)\n",
    "#                 print(f\"Length: {length} cm, Breadth: {breadth} cm, Volume: {volume} cm^3, Shell Weight: {shell_weight} g, Grade: {grade}\")\n",
    "#                 csv_data.append([filename, length, breadth, volume, shell_weight, grade])\n",
    "#                 # print(csv_data)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing image {filename}: {e}\")\n",
    "\n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)\n",
    "        writer.writerows(csv_data)\n",
    "        \n",
    "        \n",
    "    print(f\"Data written to {csv_file_path} successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4bc65319-bbd1-48fd-a18b-e60535545aa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_cocoon_grade(image_path):\n",
    "    # Load the pre-trained segmentation model (example: U-Net, Mask R-CNN)\n",
    "    # Assuming the segmentation model is already trained and available\n",
    "    model_path = \"/Users/KIIT/Desktop/Research/CTR&TI/Models/runs/segment/train32/weights/last.pt\"\n",
    "    model = YOLO(model_path)\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Perform segmentation to get the mask\n",
    "    results = model(image)\n",
    "    \n",
    "    mask = None\n",
    "    \n",
    "    for result in results:\n",
    "        if hasattr(result, 'mask'):\n",
    "            mask = result.masks.data\n",
    "            break\n",
    "    \n",
    "    if mask is None:\n",
    "        print(\"Error: No masks found\")\n",
    "        return None\n",
    "    \n",
    "    # print(type(mask))\n",
    "    # # Assuming the mask has multiple channels or a different data type\n",
    "    # if len(mask.shape) > 2:\n",
    "    #     mask = mask[:, :, 0]  # Select the first channel (assuming it represents the segmentation)\n",
    "    # mask = mask.astype(np.uint8)\n",
    "\n",
    "    # Find the contours of the cocoon\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cocoon_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Draw the contour on the original image (optional for visualization)\n",
    "    cv2.drawContours(image, [cocoon_contour], -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Calculate bounding box to get length and breadth\n",
    "    x, y, width, height = cv2.boundingRect(cocoon_contour)\n",
    "\n",
    "    # Convert pixel measurements to centimeters (assuming you know the conversion factor)\n",
    "    cm_per_pixel = 0.0264583333  # Example value, you need to calibrate this\n",
    "    length_cm = width*cm_per_pixel\n",
    "    breadth_cm = height*cm_per_pixel\n",
    "\n",
    "    # print(f\"Length: {length_cm} cm, Breadth: {breadth_cm} cm\")\n",
    "    \n",
    "    Volume = Volume_predictor(length_cm, breadth_cm)\n",
    "    \n",
    "    Shell_Weight = Shell_Weight_predictor(Volume)\n",
    "    \n",
    "    Grade = Grading(Shell_Weight)\n",
    "    \n",
    "    return length_cm, breadth_cm, Volume, Shell_Weight, Grade\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
