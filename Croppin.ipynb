{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34e8a5f7-475d-4bc4-ab8f-fa14327a7119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce7d5612-34bc-40d0-a2ab-47d634a6dd3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_contours_from_yolo(img_path, model_path):\n",
    "    # Load the YOLOv8 model\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    # Load and preprocess the input image\n",
    "    img = cv2.imread(img_path)\n",
    "    print(img.shape)\n",
    "\n",
    "    # Check if the image is loaded correctly\n",
    "    if img is None:\n",
    "        raise ValueError(\"Image not found or the path is incorrect.\")\n",
    "    \n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "\n",
    "    # Check if the image is grayscale or color\n",
    "    if len(img.shape) == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "    H, W, _ = img.shape\n",
    "\n",
    "    # Inference with the YOLOv8 model\n",
    "    results = model(img)\n",
    "\n",
    "    contours_list = []\n",
    "    bounding_rects = []\n",
    "\n",
    "    # Process each detection in the results\n",
    "    for result in results:\n",
    "        for j, mask in enumerate(result.masks.data):\n",
    "            mask = mask.cpu().numpy().astype(np.uint8) * 255  # Convert to 8-bit binary mask\n",
    "\n",
    "            # Check if mask is empty\n",
    "            if mask.size == 0:\n",
    "                raise ValueError(\"Mask is empty. Please check the model's output.\")\n",
    "            \n",
    "            print(f\"Mask shape before resize: {mask.shape}\")\n",
    "\n",
    "            # Resize mask to the original image size\n",
    "            mask = cv2.resize(mask, (W, H))\n",
    "\n",
    "            print(f\"Mask shape after resize: {mask.shape}\")\n",
    "\n",
    "            # Find the contours of the mask\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            if not contours:\n",
    "                raise ValueError(\"No contours found in the mask. Please check the mask and try again.\")\n",
    "            \n",
    "            contours_list.append(contours)\n",
    "            \n",
    "            # Compute bounding rectangles for each contour\n",
    "            for contour in contours:\n",
    "                x, y, width, height = cv2.boundingRect(contour)\n",
    "                \n",
    "                if width < 50 or height < 50:  # Adjust the threshold values as needed\n",
    "                    print(f\"Small bounding box ignored: ({x}, {y}, {width}, {height})\")\n",
    "                    continue\n",
    "                bounding_rects.append((x, y, width, height))\n",
    "                print(bounding_rects)\n",
    "                \n",
    "                # Optional: Draw the contour and bounding rectangle on the original image for visualization\n",
    "                cv2.drawContours(img, [contour], -1, (0, 255, 0), 10)\n",
    "                cv2.rectangle(img, (x, y), (x+width, y+height), (255, 0, 0), 10)\n",
    "                \n",
    "    max_width = 800\n",
    "    max_height = 600\n",
    "    img_resized = resize_image_to_fit_window(img, max_width, max_height)\n",
    "\n",
    "    cv2.imshow('Mask Contours and Bounding Rectangles', img_resized)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "            \n",
    "    return contours_list, bounding_rects, img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48529ab6-77fb-41e9-9370-558c42be32d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resize_image_to_fit_window(image, max_width, max_height):\n",
    "    height, width = image.shape[:2]\n",
    "    if width > max_width or height > max_height:\n",
    "        scaling_factor = min(max_width / width, max_height / height)\n",
    "        new_size = (int(width * scaling_factor), int(height * scaling_factor))\n",
    "        return cv2.resize(image, new_size)\n",
    "    else:\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9902442-54d9-4902-8642-f4ab91c759a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cropping(bounding_rect, img_path):\n",
    "    # for i, rect in enumerate(bounding_rects):\n",
    "    x, y, w, h = bounding_rects[0]\n",
    "    x1 = x+int(w/2)\n",
    "    print(x1)\n",
    "    y1 = y+int(h/2)\n",
    "    print(y1)\n",
    "    add_w = int(2051/2)\n",
    "    print(add_w)\n",
    "    add_h = int(2811/2)\n",
    "    print(add_h)\n",
    "    x2 = x1-add_w\n",
    "    print(x2)\n",
    "    y2 = y1-add_h\n",
    "    print(y2)\n",
    "    h1 = 2811\n",
    "    print(h1)\n",
    "    w1 = 2051\n",
    "    print(w1)\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    # sub_rect = image[y2:y2+h, x2:x2+w]\n",
    "    # resized_sub_rect = cv2.resize(sub_rect, (w1, h1))\n",
    "    # cv2.rectangle(image, (x2, y2), (x2+w1, y2+h1), (255, 0, 0), 10)\n",
    "    # x2 = max(0, x2)\n",
    "    # y2 = max(0, y2)\n",
    "    # end_x = min(image.shape[1], x2 + w1)\n",
    "    # end_y = min(image.shape[0], y2 + h1)\n",
    "    \n",
    "    image = image[y2:y2+h1, x2:x2+w1]\n",
    "    view_image(\"Resized\",image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d8b823d-8f2a-4e43-ac57-427ce8580b74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def view_image(window_name, image, max_width=400, max_height=200):\n",
    "    # Get the dimensions of the image\n",
    "    image = resize_image_to_fit_window(image, max_width, max_height)\n",
    "    \n",
    "    # Display the image\n",
    "    cv2.imshow(window_name, image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff6b35b7-d59c-4622-8c44-36101c411dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter image path:  C:/Users/KIIT/Desktop/Research/CTR&TI/Models/dataset/25Cocoons/DSC03610.JPG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3672, 4896, 3)\n",
      "Image shape: (3672, 4896, 3)\n",
      "\n",
      "0: 480x640 1 Cocoon, 240.2ms\n",
      "Speed: 8.5ms preprocess, 240.2ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Mask shape before resize: (480, 640)\n",
      "Mask shape after resize: (3672, 4896)\n",
      "[(2092, 1297, 666, 1124)]\n",
      "2425\n",
      "1859\n",
      "1025\n",
      "1405\n",
      "1400\n",
      "454\n",
      "2811\n",
      "2051\n",
      "[[[ 85  85  85]\n",
      "  [ 90  90  90]\n",
      "  [ 91  91  91]\n",
      "  ...\n",
      "  [104 102 101]\n",
      "  [102 100  99]\n",
      "  [ 99  97  96]]\n",
      "\n",
      " [[ 87  87  87]\n",
      "  [ 92  92  92]\n",
      "  [100 100 100]\n",
      "  ...\n",
      "  [ 99  97  96]\n",
      "  [ 92  90  89]\n",
      "  [ 96  94  93]]\n",
      "\n",
      " [[ 88  91  89]\n",
      "  [ 94  97  95]\n",
      "  [107 108 106]\n",
      "  ...\n",
      "  [ 91  92  90]\n",
      "  [ 89  90  88]\n",
      "  [ 87  88  86]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 49  55  54]\n",
      "  [ 49  55  54]\n",
      "  [ 49  55  54]\n",
      "  ...\n",
      "  [ 54  63  60]\n",
      "  [ 51  60  57]\n",
      "  [ 49  58  55]]\n",
      "\n",
      " [[ 46  52  51]\n",
      "  [ 46  52  51]\n",
      "  [ 44  50  49]\n",
      "  ...\n",
      "  [ 49  60  57]\n",
      "  [ 48  59  56]\n",
      "  [ 49  58  55]]\n",
      "\n",
      " [[ 47  52  51]\n",
      "  [ 46  51  50]\n",
      "  [ 49  55  54]\n",
      "  ...\n",
      "  [ 52  61  58]\n",
      "  [ 47  56  53]\n",
      "  [ 46  55  52]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = input(\"Enter image path: \")\n",
    "model_path = '/Users/KIIT/Desktop/Research/CTR&TI/Models/runs/segment/train32/weights/last.pt'  # Path to your trained YOLOv8 model\n",
    "\n",
    "\n",
    "contours_list, bounding_rects, img= find_contours_from_yolo(img_path, model_path)\n",
    "cropped_image = cropping(bounding_rects,img_path)\n",
    "print(cropped_image)\n",
    "view_image(\"Original\",img)\n",
    "view_image(\"Resized\",cropped_image)\n",
    "\n",
    "# cv2.imwrite('original_sub_rectangle.jpg', sub_rect)\n",
    "cv2.imwrite('resized.jpg', cropped_image)\n",
    "# # for i, contours in enumerate(contours_list):\n",
    "# #     print(f\"Contours for mask {i}: {contours}\")\n",
    "\n",
    "# length, breadth, volume, shell_weight, grade = predict_cocoon_1(bounding_rects)\n",
    "# print(f\"Length: {length} cm, Breadth: {breadth} cm, Volume: {volume} cm^3, Shell Weight: {shell_weight} g, Grade: {grade}\")\n",
    "# # csv.data[length, breadth, volume, shell_weight, grade]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e0232-6f0b-4349-a033-b59fd19ce517",
   "metadata": {},
   "outputs": [],
   "source": [
    "(2092, 1664, 727, 1224)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
